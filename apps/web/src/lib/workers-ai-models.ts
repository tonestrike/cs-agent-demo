export const WORKERS_AI_MODELS = [
  "@cf/aisingapore/gemma-sea-lion-v4-27b-it",
  "@cf/deepseek-ai/deepseek-math-7b-instruct",
  "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
  "@cf/defog/sqlcoder-7b-2",
  "@cf/fblgit/una-cybertron-7b-v2-bf16",
  "@cf/google/gemma-2b-it-lora",
  "@cf/google/gemma-3-12b-it",
  "@cf/google/gemma-7b-it-lora",
  "@cf/ibm-granite/granite-4.0-h-micro",
  "@cf/meta-llama/llama-2-7b-chat-hf-lora",
  "@cf/meta/llama-2-7b-chat-fp16",
  "@cf/meta/llama-2-7b-chat-int8",
  "@cf/meta/llama-3-8b-instruct",
  "@cf/meta/llama-3-8b-instruct-awq",
  "@cf/meta/llama-3.1-70b-instruct",
  "@cf/meta/llama-3.1-8b-instruct",
  "@cf/meta/llama-3.1-8b-instruct-awq",
  "@cf/meta/llama-3.1-8b-instruct-fast",
  "@cf/meta/llama-3.1-8b-instruct-fp8",
  "@cf/meta/llama-3.2-11b-vision-instruct",
  "@cf/meta/llama-3.2-1b-instruct",
  "@cf/meta/llama-3.2-3b-instruct",
  "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
  "@cf/meta/llama-4-scout-17b-16e-instruct",
  "@cf/meta/llama-guard-3-8b",
  "@cf/microsoft/phi-2",
  "@cf/mistral/mistral-7b-instruct-v0.1",
  "@cf/mistral/mistral-7b-instruct-v0.2-lora",
  "@cf/mistralai/mistral-small-3.1-24b-instruct",
  "@cf/openai/gpt-oss-120b",
  "@cf/openai/gpt-oss-20b",
  "@cf/openchat/openchat-3.5-0106",
  "@cf/qwen/qwen1.5-0.5b-chat",
  "@cf/qwen/qwen1.5-1.8b-chat",
  "@cf/qwen/qwen1.5-14b-chat-awq",
  "@cf/qwen/qwen1.5-7b-chat-awq",
  "@cf/qwen/qwen2.5-coder-32b-instruct",
  "@cf/qwen/qwen3-30b-a3b-fp8",
  "@cf/qwen/qwq-32b",
  "@cf/thebloke/discolm-german-7b-v1-awq",
  "@cf/tiiuae/falcon-7b-instruct",
  "@cf/tinyllama/tinyllama-1.1b-chat-v1.0",
  "@hf/google/gemma-7b-it",
  "@hf/meta-llama/meta-llama-3-8b-instruct",
  "@hf/mistral/mistral-7b-instruct-v0.2",
  "@hf/nexusflow/starling-lm-7b-beta",
  "@hf/nousresearch/hermes-2-pro-mistral-7b",
  "@hf/thebloke/deepseek-coder-6.7b-base-awq",
  "@hf/thebloke/deepseek-coder-6.7b-instruct-awq",
  "@hf/thebloke/llama-2-13b-chat-awq",
  "@hf/thebloke/llamaguard-7b-awq",
  "@hf/thebloke/mistral-7b-instruct-v0.1-awq",
  "@hf/thebloke/neural-chat-7b-v3-1-awq",
  "@hf/thebloke/openhermes-2.5-mistral-7b-awq",
  "@hf/thebloke/zephyr-7b-beta-awq",
] as const;

export const OPENROUTER_MODELS = [
  "openai/gpt-5-mini",
  "openai/gpt-4.1-mini",
  "openai/gpt-4.1",
  "openai/gpt-4o-mini",
  "openai/gpt-4o",
  "anthropic/claude-3.5-sonnet",
  "anthropic/claude-3.5-haiku",
] as const;

export const JSON_MODE_MODELS = [
  "@cf/meta/llama-3.1-8b-instruct-fast",
  "@cf/meta/llama-3.1-70b-instruct",
  "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
  "@cf/meta/llama-3-8b-instruct",
  "@cf/meta/llama-3.1-8b-instruct",
  "@cf/meta/llama-3.2-11b-vision-instruct",
  "@hf/nousresearch/hermes-2-pro-mistral-7b",
  "@hf/thebloke/deepseek-coder-6.7b-instruct-awq",
  "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
  "openai/gpt-5-mini",
  "openai/gpt-4.1-mini",
  "openai/gpt-4.1",
  "openai/gpt-4o-mini",
  "openai/gpt-4o",
] as const;

const jsonModeSet = new Set<string>(JSON_MODE_MODELS);

export const isJsonModeModel = (modelId: string) => jsonModeSet.has(modelId);

const openRouterSet = new Set<string>(OPENROUTER_MODELS);

export const isOpenRouterModel = (modelId: string) =>
  openRouterSet.has(modelId);
